{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bl1-bl2-30min-60min place coding cell evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.getipython import get_ipython\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "sys.path.append(\"..\")\n",
    "from placecode import utils as ut\n",
    "from placecode.from_caiman import *\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "except NameError:\n",
    "    pass\n",
    "from datetime import datetime\n",
    "import scipy\n",
    "from scipy.ndimage import gaussian_filter1d  # smooth signal strength maps\n",
    "\n",
    "sns.set(font_scale=3)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = False\n",
    "if save_figs:\n",
    "    file_extension = \".pdf\"\n",
    "    output_folder = ut.open_dir(\"Choose folder to save figures\")\n",
    "    print(f\"Saving figures as {file_extension} is turned on. Saving figures to {output_folder}\")\n",
    "    now = datetime.now()\n",
    "    datetime_str = f\"{now.year:04}{datetime.now().month:02}{datetime.now().day:02}-{datetime.now().hour:02}{datetime.now().minute:02}{datetime.now().second:02}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open (hdf5) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(files_list, dict_mouse_data):\n",
    "    Y_list = []\n",
    "    A_list = []\n",
    "    dims_list = []  # Cn entry in workspace # TODO: A_sparse always have lower resolution, probably from cropping... should I define that as dims?\n",
    "    templates = []  # TODO: add templates to hdf5 files.. caiman unfortunately does not save them for some reason. need to manually care about this.\n",
    "    p_vals = []\n",
    "    conditions = []\n",
    "    tv_angles = []\n",
    "    tv_lengths = []\n",
    "    ssm_zs = []\n",
    "    ssm_event_masks = []\n",
    "    mouse_ids = []\n",
    "    for fpath in files_list:\n",
    "        with h5py.File(fpath, \"r\") as hf:\n",
    "            mouse_id = hf.attrs[\"mouse_id\"]\n",
    "            resolution = hf.attrs[\"resolution\"][()]\n",
    "            n_components = hf.attrs[\"n_units\"]\n",
    "            condition = hf.attrs[\"condition\"]\n",
    "            ps = hf[\"p_values_tuned\"][()]\n",
    "            A_data = hf[\"A_data\"][()]\n",
    "            A_indices = hf[\"A_indices\"][()]\n",
    "            A_indptr = hf[\"A_indptr\"][()]\n",
    "            A_shape = hf[\"A_shape\"][()]\n",
    "            tv_a = hf[\"tuned_vector_angles\"][()]\n",
    "            tv_l = hf[\"tuned_vector_lengths\"][()]\n",
    "            ssm_z = hf[\"ssm_z\"][()]\n",
    "            ssm_event_mask = hf[\"ssm_events_mask\"][()]\n",
    "            #spatial = ut.read_spatial(A_data, A_indices, A_indptr, A_shape, n_components, resolution, unflatten=False)\n",
    "            spatial = scipy.sparse.csc_matrix((A_data, A_indices, A_indptr), shape=A_shape)\n",
    "            dims_list.append(resolution)\n",
    "            A_list.append(spatial)  # need to swap: (n_units, n_pixels) -> (n_pixels, n_units)\n",
    "            p_vals.append(ps)\n",
    "            conditions.append(condition)\n",
    "            tv_angles.append(tv_a)\n",
    "            tv_lengths.append(tv_l)\n",
    "            ssm_zs.append(ssm_z)\n",
    "            mouse_ids.append(mouse_id)\n",
    "            ssm_event_masks.append(ssm_event_mask)\n",
    "    for m_id in mouse_ids[1:]:  # make sure all data belongs to same mouse\n",
    "        assert m_id == mouse_ids[0]\n",
    "    mouse_id = mouse_ids[0]\n",
    "    \n",
    "    dict_mouse_data[mouse_id] = {\"Y_list\": Y_list, \"A_list\": A_list, \"dims_list\": dims_list, \"templates\": templates, \"p_vals\": p_vals, \"conditions\":conditions, \"tv_angles\": tv_angles, \"tv_lengths\": tv_lengths, \"ssm_zs\": ssm_zs, \"ssm_event_masks\": ssm_event_masks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mouse_data = dict()  # \n",
    "i_mouse = 1\n",
    "next_mouse = True\n",
    "while next_mouse:\n",
    "    files_list = []\n",
    "    conditions = [\"bl1\", \"bl2\", \"30min\", \"60min\"]\n",
    "    for cond in conditions:\n",
    "        fpath = ut.open_file(f\"Mouse #{i_mouse}: Open hdf5 file for time point {cond}\")\n",
    "        if fpath == \".\":  # user pressed cancel\n",
    "            next_mouse = False\n",
    "            break\n",
    "        else:\n",
    "            files_list.append(fpath)\n",
    "    if len(conditions) == len(files_list): \n",
    "        extract_data(files_list, dict_mouse_data)\n",
    "    else:\n",
    "        if len(files_list) > 0:  # do not throw error if no files at all chosen for next mouse\n",
    "            raise Exception(f\"Not enough files chosen! Expected {len(conditions)}, received {len(files_list)}\")\n",
    "    i_mouse += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_np(list_of_arrs):\n",
    "    \"\"\"\n",
    "    given a list of 1D arrays, convert to a 2D array, add padding with np.nans to achieve equal column sizes \n",
    "    \"\"\"\n",
    "    return np.array([np.concatenate([lst, [np.nan]*(max_len - len(lst))]) for lst in list_of_arrs]).T\n",
    "\n",
    "for mouse_id in dict_mouse_data.keys():\n",
    "    tv_angles = dict_mouse_data[mouse_id][\"tv_angles\"]\n",
    "    tv_lengths = dict_mouse_data[mouse_id][\"tv_lengths\"]\n",
    "    p_vals = dict_mouse_data[mouse_id][\"p_vals\"]\n",
    "\n",
    "    # convert tuned vector data into numpy array. To deal with varying number of units per recording (condition), pad each column to the longest with np.nan\n",
    "    max_len = max(len(lst) for lst in tv_angles) \n",
    "\n",
    "    dict_mouse_data[mouse_id][\"tv_angles_padded\"] = convert_to_np(tv_angles)\n",
    "    dict_mouse_data[mouse_id][\"tv_lengths_padded\"] = convert_to_np(tv_lengths)\n",
    "    dict_mouse_data[mouse_id][\"p_vals_padded\"] = convert_to_np(p_vals)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse_id in dict_mouse_data.keys():\n",
    "    templates = dict_mouse_data[mouse_id][\"templates\"]\n",
    "    dims_list = dict_mouse_data[mouse_id][\"dims_list\"]\n",
    "    if len(templates) > 0:\n",
    "        templates_cropped = []\n",
    "        for template in templates:\n",
    "            FOV_shape = template.shape\n",
    "            cropped_shape = dims_list[0]\n",
    "            \n",
    "            x_crop_onesided = (FOV_shape[0] - cropped_shape[0])//2\n",
    "            assert 2*x_crop_onesided == FOV_shape[0] - cropped_shape[0]\n",
    "\n",
    "            y_crop_onesided = (FOV_shape[1] - cropped_shape[1])//2\n",
    "            assert 2*y_crop_onesided == FOV_shape[1] - cropped_shape[1]\n",
    "            template_cropped = template[y_crop_onesided:-y_crop_onesided,x_crop_onesided:-x_crop_onesided]  # TODO: x and y swapped?\n",
    "            templates_cropped.append(template_cropped)\n",
    "        dict_mouse_data[mouse_id][\"templates_cropped\"] = templates_cropped\n",
    "    # TODO: use templates for multisession registration\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `register_multisession()`\n",
    "\n",
    "The function `register_multisession()` requires 3 arguments:\n",
    "- `A`: A list of ndarrays or scipy.sparse.csc matrices with (# pixels X # component ROIs) for each session\n",
    "- `dims`: Dimensions of the FOV, needed to restore spatial components to a 2D image\n",
    "- `templates`: List of ndarray matrices of size `dims`, template image of each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mice = len(dict_mouse_data.keys())\n",
    "for i_mouse, mouse_id in enumerate(dict_mouse_data.keys()):\n",
    "    print(f\"Working on {mouse_id}, mouse #{i_mouse+1}/{n_mice}\")\n",
    "    A_list = dict_mouse_data[mouse_id][\"A_list\"]\n",
    "    dims_list = dict_mouse_data[mouse_id][\"dims_list\"]\n",
    "    spatial_union, assignments, matchings = register_multisession(A=A_list, dims=dims_list[0])\n",
    "    dict_mouse_data[mouse_id][\"spatial_union\"] = spatial_union\n",
    "    dict_mouse_data[mouse_id][\"assignments\"] = assignments\n",
    "    dict_mouse_data[mouse_id][\"matchings\"] = matchings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns 3 variables for further analysis:\n",
    "- `spatial_union`: csc_matrix (# pixels X # total distinct components), the union of all ROIs across all sessions aligned to the FOV of the last session.\n",
    "- `assignments`: ndarray (# total distinct components X # sessions). `assignments[i,j]=k` means that component `k` from session `j` has been identified as component `i` from the union of all components, otherwise it takes a `NaN` value. Note that for each `i` there is at least one session index `j` where `assignments[i,j]!=NaN`.\n",
    "- `matchings`: list of (# sessions) lists. Saves `spatial_union` indices of individual components in each session. `matchings[j][k] = i` means that component `k` from session `j` is represented by component `i` in the union of all components `spatial_union`. In other words `assignments[matchings[j][k], j] = j`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: extract as function that takes lists or something.\n",
    "# Goal: be able to use it for plotting various scenarios: plot all cells, plot cell categories (red=PC, ...)\n",
    "#   plot stable baseline cells as red, all rest as grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(n_mice, len(conditions), figsize=(24, 24))\n",
    "\n",
    "use_continuous_cmap = False\n",
    "if use_continuous_cmap:\n",
    "    cm = plt.get_cmap('gist_rainbow')\n",
    "    colors_arr = cm(np.linspace(0, 1, 30))\n",
    "    i_shuffled_colors=np.arange(len(colors_arr))  # shuffle colors\n",
    "    np.random.shuffle(i_shuffled_colors)\n",
    "    colors_arr = colors_arr[i_shuffled_colors]\n",
    "else:\n",
    "    cm = plt.get_cmap(\"tab20\")\n",
    "    colors_arr = cm(np.linspace(0, 1, 20))\n",
    "\n",
    "for i_id, mouse_id in enumerate(dict_mouse_data.keys()):\n",
    "    print(mouse_id)\n",
    "    assignments = dict_mouse_data[mouse_id][\"assignments\"]  # (n_independent_components, n_conditions)\n",
    "    n_conditions = assignments.shape[1]\n",
    "    dims = dict_mouse_data[mouse_id][\"dims_list\"][0]  # should be [512, 512]\n",
    "    dims_4d = dims.copy()\n",
    "    dims_4d = np.concatenate([dims_4d,[3]])  # RGB colors\n",
    "    dims_4d = np.concatenate([dims_4d, [n_conditions]])  # individual conditions\n",
    "    frames = np.zeros(dims_4d)  # shape (x, y, 3, n_conditions) create image data to show for each condition.\n",
    "    # go over each assignment row (same cells over all conditions). Add colored pixel\n",
    "    for i_component in range(assignments.shape[0]):\n",
    "        idxs_component = assignments[i_component]\n",
    "        rgba = colors_arr[i_component%len(colors_arr)]  # cycle over the colors\n",
    "        # for each condition, add spatial component of cell to image as specific colored pixels\n",
    "        for i_condition in range(n_conditions):\n",
    "            i_cell = idxs_component[i_condition]\n",
    "            if not np.isnan(i_cell):  # if nan, no presence of cell was found in that condition\n",
    "                i_cell = int(i_cell)\n",
    "                # set the cell pixels to the corresponding r, g, b\n",
    "                for i_color in range(3):  # r, g, b\n",
    "                    frames[dict_mouse_data[mouse_id][\"A_list\"][i_condition][:, i_cell].todense().reshape((512, 512)) > 0, i_color, i_condition] = rgba[i_color]\n",
    "    for i_condition, condition in enumerate(conditions):\n",
    "        ax = axs[i_id, i_condition]\n",
    "        ax.title.set_text(f\"{mouse_id} - {condition}\")\n",
    "        ax.imshow(frames[:,:,:, i_condition])\n",
    "        ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"stable baseline place coding cells\"\n",
    "i.e. cells that were place coding in both baseline recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse_id in dict_mouse_data.keys():\n",
    "    print(mouse_id)\n",
    "    p_vals = dict_mouse_data[mouse_id][\"p_vals\"] \n",
    "    assignments = dict_mouse_data[mouse_id][\"assignments\"]\n",
    "\n",
    "    # drop all cells with nan in any of the bl\n",
    "    assignments_stable_bl_pc = assignments[np.logical_and(~np.isnan(assignments[:, 0]), ~np.isnan(assignments[:, 1]))]\n",
    "    # filter assignments to place coding cells in first bl\n",
    "    #   sort assignment in first bl\n",
    "    print(f\"Number of cells with p-value in both bl: {len(assignments_stable_bl_pc)}\")\n",
    "    idx_sorted_bl1 = np.argsort(assignments_stable_bl_pc[:, 0])\n",
    "    assignments_stable_bl_pc = assignments_stable_bl_pc[idx_sorted_bl1]\n",
    "    #   take only place cells\n",
    "    idx_pc_bl1 = np.nonzero(p_vals[0][assignments_stable_bl_pc[:, 0].astype(np.int32)] <= 0.05)[0]  # indices of place coding cells in bl1\n",
    "    assignments_stable_bl_pc = assignments_stable_bl_pc[idx_pc_bl1]\n",
    "    print(f\"Number of bl1 pc cells: {len(assignments_stable_bl_pc)}\")\n",
    "\n",
    "    # filter pc in second bl\n",
    "    #   sort assignment in second bl\n",
    "    idx_sorted_bl2 = np.argsort(assignments_stable_bl_pc[:, 1])\n",
    "    assignments_stable_bl_pc = assignments_stable_bl_pc[idx_sorted_bl2]\n",
    "    #   take place cells\n",
    "    idx_pc_bl2 = np.nonzero(p_vals[1][assignments_stable_bl_pc[:, 1].astype(np.int32)] <= 0.05)[0]  # indices of place coding cells in bl2\n",
    "    assignments_stable_bl_pc = assignments_stable_bl_pc[idx_pc_bl2]\n",
    "    print(f\"Number of bl1+bl2 pc cells: {len(assignments_stable_bl_pc)}\")\n",
    "\n",
    "    # check that indeed no nans left in baseline\n",
    "    assert ~np.isnan(assignments_stable_bl_pc[:,0]).any()\n",
    "    assert ~np.isnan(assignments_stable_bl_pc[:,1]).any()\n",
    "    # check that indeed all the cells ar place coding in baselines\n",
    "    assert (p_vals[0][assignments_stable_bl_pc[:,0].astype(np.int32)] <= 0.05).all()\n",
    "    assert(p_vals[1][assignments_stable_bl_pc[:,1].astype(np.int32)] <= 0.05).all()\n",
    "\n",
    "    dict_mouse_data[mouse_id][\"assignments_stable_bl_pc\"] = assignments_stable_bl_pc\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot stable baseline cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse_id in dict_mouse_data.keys():\n",
    "    assignments_stable_bl_pc = dict_mouse_data[mouse_id][\"assignments_stable_bl_pc\"] \n",
    "    print(len(assignments_stable_bl_pc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(assignments_stable_bl_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse_id in dict_mouse_data.keys():\n",
    "    assignments = dict_mouse_data[mouse_id][\"assignments\"] \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sankey-plot of stable initial place coding cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mouse_data[\"WEZ8917\"][\"assignments_stable_bl_pc\"][:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mouse_data[\"WEZ8917\"][\"assignments_stable_bl_pc\"][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(10)\n",
    "b = np.array([1, 2, 3])\n",
    "a[:len(b)] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [] \n",
    "colors= []\n",
    "xs = []  # location of boxes\n",
    "ys = []\n",
    "# PC cells: p value <= 0.05, assignment exists\n",
    "# nPC cells: p value > 0.05, assignment exists\n",
    "# LA cells: p value == np.nan, assignment exists\n",
    "# IN cells: assignment does not exist\n",
    "\n",
    "n_classes = 4  # PC, nPC, LA (low activity), IN (invisible)\n",
    "for i_condition, condition in enumerate(conditions):\n",
    "  labels.extend([f\"PC {condition}\", f\"nPC {condition}\", f\"lowA {condition}\", f\"invisible {condition}\"])  # for each condition, check categories PC and not-PC\n",
    "  colors.extend([\"red\", \"blue\", \"slategrey\", \"black\"])\n",
    "  xs.extend([0.2*i_condition]*n_classes)\n",
    "  ys.extend([0.2*i for i in range(n_classes)])\n",
    "n_conditions = len(conditions)\n",
    "\n",
    "# in each condition, we have 4 categories, each have 4 targets in the next category\n",
    "sources = []  # should be 0, 1, 2, 3, 0, 1, 2, 3, ..., 0, 1, 2, 3, 4, 5, 6, 7, ...\n",
    "targets = []  # should be 4, 4, 4, 4, 5, 5, 5, 5, ..., 7, 7, 7, 7, 8, 8, 8, 8, ...\n",
    "values = []\n",
    "link_colors = []\n",
    "n_cells = len(dict_mouse_data[\"WEZ8917\"][\"assignments_stable_bl_pc\"][:, 0])\n",
    "\n",
    "for i_condition in range(n_conditions-1):  # last condition does not have output\n",
    "  print(i_condition)\n",
    "  # get PC+nPC+LA cell indices sorted by first baseline\n",
    "  idx_cells_source = dict_mouse_data[\"WEZ8917\"][\"assignments_stable_bl_pc\"][:, i_condition]\n",
    "  idx_cells_source = idx_cells_source[~np.isnan(idx_cells_source)].astype(np.int32)\n",
    "  idx_cells_target = dict_mouse_data[\"WEZ8917\"][\"assignments_stable_bl_pc\"][:, i_condition+1]\n",
    "  idx_cells_target = idx_cells_target[~np.isnan(idx_cells_target)].astype(np.int32)\n",
    "\n",
    "  # get p values, indices matched (i. e. first p value is for the same neuron in both list)\n",
    "  # set p values as following:\n",
    "  #   PC, nPC: keep original p\n",
    "  #   LA: keep np.nan as p\n",
    "  #   IN: set p to -1 (<0)\n",
    "  p_vals_source = np.full(n_cells, -1.0)  # set default value to invisible cell p value\n",
    "  p_vals_target = np.full(n_cells, -1.0)  # set default value to invisible cell p value\n",
    "\n",
    "  # set PC, nPC, LA cell p values\n",
    "  p_vals_temp = dict_mouse_data[\"WEZ8917\"][\"p_vals\"][i_condition][idx_cells_source]\n",
    "  assert n_cells >= len(p_vals_temp)\n",
    "  p_vals_source[:len(p_vals_temp)] = p_vals_temp\n",
    "  p_vals_temp = dict_mouse_data[\"WEZ8917\"][\"p_vals\"][i_condition][idx_cells_target]\n",
    "  assert n_cells >= len(p_vals_temp)\n",
    "  p_vals_target[:len(p_vals_temp)] = p_vals_temp \n",
    "\n",
    "  # PC, nPC, lowA, invisible sources flow to PC in target\n",
    "  # i. e. PC[i_condition] -> PC[i_condition+1], nPC[i_condition] -> PC[i_condition+1], LA[i_condition] -> PC[i_condition+1], IN[i_condition] -> PC[i_condition+1]\n",
    "  n_PC_to_PC = np.sum(np.logical_and(p_vals_source <= 0.05,  p_vals_target <= 0.05))\n",
    "  n_nPC_to_PC = np.sum(np.logical_and(p_vals_source > 0.05,  p_vals_target <= 0.05))\n",
    "  n_LA_to_PC = np.sum(np.logical_and(np.isnan(p_vals_source),  p_vals_target <= 0.05))\n",
    "  n_IN_to_PC = np.sum(np.logical_and(p_vals_source < 0, p_vals_target <= 0.05))  # np.sum(np.logical_and(p_vals_source <= 0.05,  p_vals_target <= 0.05))\n",
    "  sources.extend([n_classes*i_condition, n_classes*i_condition+1, n_classes*i_condition+2, n_classes*i_condition+3])\n",
    "  targets.extend([n_classes*(i_condition+1), n_classes*(i_condition+1), n_classes*(i_condition+1), n_classes*(i_condition+1)])\n",
    "  values.extend([n_PC_to_PC, n_nPC_to_PC, n_LA_to_PC, n_IN_to_PC])\n",
    "  link_colors.extend([\"rgba(255, 0, 0, 0.4)\", \"rgba(0, 0, 255, 0.4)\", \"rgba(220,220,220, 0.4)\", \"rgba(255, 255, 255, 0.4)\"])  # PC -> x is light blue, nPC -> x is light red\n",
    "  \n",
    "  # PC and nPC sources flow to nPC in target\n",
    "  # i. e. PC[i_condition] -> nPC[i_condition+1], nPC[i_condition] -> nPC[i_condition+1] ...\n",
    "  n_PC_to_nPC = np.sum(np.logical_and(p_vals_source <= 0.05,  p_vals_target > 0.05))\n",
    "  n_nPC_to_nPC = np.sum(np.logical_and(p_vals_source > 0.05,  p_vals_target > 0.05))\n",
    "  n_LA_to_nPC = np.sum(np.logical_and(np.isnan(p_vals_source),  p_vals_target > 0.05))\n",
    "  n_IN_to_nPC = np.sum(np.logical_and(p_vals_source < 0, p_vals_target > 0.05))\n",
    "  sources.extend([n_classes*i_condition, n_classes*i_condition+1, n_classes*i_condition+2, n_classes*i_condition+3])\n",
    "  targets.extend([n_classes*(i_condition+1)+1, n_classes*(i_condition+1)+1, n_classes*(i_condition+1)+1, n_classes*(i_condition+1)+1])\n",
    "  values.extend([n_PC_to_nPC, n_nPC_to_nPC, n_LA_to_nPC, n_IN_to_nPC])\n",
    "  link_colors.extend([\"rgba(255, 0, 0, 0.4)\", \"rgba(0, 0, 255, 0.4)\", \"rgba(220,220,220, 0.4)\", \"rgba(255, 255, 255, 0.4)\"])  # PC -> x is light blue, nPC -> x is light red\n",
    "\n",
    "  # PC, nPC, LA, IN sources flow to LA in target\n",
    "  n_PC_to_LA = np.sum(np.logical_and(p_vals_source <= 0.05,  np.isnan(p_vals_target)))\n",
    "  n_nPC_to_LA = np.sum(np.logical_and(p_vals_source > 0.05,  np.isnan(p_vals_target)))\n",
    "  n_LA_to_LA = np.sum(np.logical_and(np.isnan(p_vals_source),  np.isnan(p_vals_target)))\n",
    "  n_IN_to_LA = np.sum(np.logical_and(p_vals_source < 0, np.isnan(p_vals_target)))\n",
    "  sources.extend([n_classes*i_condition, n_classes*i_condition+1, n_classes*i_condition+2, n_classes*i_condition+3])\n",
    "  targets.extend([n_classes*(i_condition+1)+2, n_classes*(i_condition+1)+2, n_classes*(i_condition+1)+2, n_classes*(i_condition+1)+2])\n",
    "  values.extend([n_PC_to_LA, n_nPC_to_LA, n_LA_to_LA, n_IN_to_LA])\n",
    "  link_colors.extend([\"rgba(255, 0, 0, 0.4)\", \"rgba(0, 0, 255, 0.4)\", \"rgba(220,220,220, 0.4)\", \"rgba(255, 255, 255, 0.4)\"])  # PC -> x is light blue, nPC -> x is light red\n",
    "\n",
    "  # PC, nPC, LA, IN sources flow to IN in target\n",
    "  n_PC_to_IN = np.sum(np.logical_and(p_vals_source <= 0.05,  p_vals_target < 0))\n",
    "  n_nPC_to_IN = np.sum(np.logical_and(p_vals_source > 0.05,  p_vals_target < 0))\n",
    "  n_LA_to_IN = np.sum(np.logical_and(np.isnan(p_vals_source),  p_vals_target < 0))\n",
    "  n_IN_to_IN = np.sum(np.logical_and(p_vals_source < 0, p_vals_target < 0))\n",
    "\n",
    "  sources.extend([n_classes*i_condition, n_classes*i_condition+1, n_classes*i_condition+2, n_classes*i_condition+3])\n",
    "  targets.extend([n_classes*(i_condition+1)+3, n_classes*(i_condition+1)+3, n_classes*(i_condition+1)+3, n_classes*(i_condition+1)+3])\n",
    "  values.extend([n_PC_to_IN, n_nPC_to_IN, n_LA_to_IN, n_IN_to_IN])\n",
    "  link_colors.extend([\"rgba(255, 0, 0, 0.4)\", \"rgba(0, 0, 255, 0.4)\", \"rgba(220,220,220, 0.4)\", \"rgba(255, 255, 255, 0.4)\"])  # PC -> x is light blue, nPC -> x is light red\n",
    "\n",
    "\n",
    "#xs = [0.0, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.4, 0.6, 0.6, 0.6, 0.6]\n",
    "#ys = [0.5, 0.2, 0.4, 0.6, 0.8, 0.2, 0.4, 0.6, 0.3, 0.7, 0.3, 0.7]\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "  arrangement=\"freeform\",\n",
    "    node = dict(\n",
    "      pad = 10,\n",
    "      #thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = labels,\n",
    "      color = colors,\n",
    "      x = xs,\n",
    "      y = ys,\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = sources, # indices correspond to labels, eg A1, A2, A1, B1, ...\n",
    "      target = targets,\n",
    "      value = values,\n",
    "      color=link_colors\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"PC-nPC-LA-IN\", font_size=10)\n",
    "#fig.write_html(\"D:\\\\Downloads\\\\pc_npc.html\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: the connection numbers are not good. Add assert that input equals output flow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(xs)):\n",
    "    print(f\"{labels[i]}: {xs[i]} {ys[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(go.Sankey(\n",
    "    arrangement = \"snap\",\n",
    "    node = {\n",
    "        \"label\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"],\n",
    "        \"x\": [0.2, 0.2, 0.5, 0.7, 0.3, 0.5, 0.5],\n",
    "        \"y\": [0.7, 0.5, 0.2, 0.4, 0.2, 0.3, 1.0],\n",
    "        'pad':10},  # 10 Pixels\n",
    "    link = {\n",
    "        \"source\": [0, 0, 1, 2, 5, 4, 3, 5, 1, 4],\n",
    "        \"target\": [5, 3, 4, 3, 0, 2, 2, 3, 6, 6],\n",
    "        \"value\": [1, 2, 1, 1, 1, 1, 1, 2, 2, 3]}))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: despite low quantity, make the shankey plot for pooled place cells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "placecoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
