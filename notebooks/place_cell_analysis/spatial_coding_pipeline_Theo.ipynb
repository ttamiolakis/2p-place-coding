{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore,kstest\n",
    "import seaborn as sns\n",
    "\n",
    "#from placecode.expinfo import MultipleFilesFoundError\n",
    "\n",
    "#import my functions\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from placecode.spatial_coding_functions import make_firing_rate_maps,make_binary,adding_parameters,cell_morphology,TunedVector,KstestPlaceCells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the folder with the data\n",
    "\n",
    "home_folder=f\"{exported_data_folder}/{mouse_ID}/{mouse_ID}_{condition}\"\n",
    "\n",
    "data_folder=f'{home_folder}' #r means that I will treat the string as a raw string (/ are special characters)\n",
    "results_folder=f'{home_folder}'\n",
    "\n",
    "# Check if results folder exists, create it if not\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "cnmf_file=glob.glob(f\"{home_folder}/*.hdf5\") #data from cnmf\n",
    "belt_file=glob.glob(f\"{home_folder}/*.h5\") #data from lab view and lfp\n",
    "\n",
    "#check that there is only one file out of each\n",
    "\n",
    "if len(cnmf_file)>1 or len(belt_file)>1:\n",
    "    raise MultipleFilesFoundError(\"error.two files with similar conditions found\")\n",
    "else:\n",
    "    print (\"all good with naming the files. continue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since glob glob is a list I take the first element out of belt file and cmf file. I have checked begore that it is only one\n",
    "\n",
    "\n",
    "cnmf_file,belt_file=cnmf_file[0],belt_file[0]\n",
    "\n",
    "#preprocessing the data\n",
    "\n",
    "#opening the hpf5 file\n",
    "fluo_hdf=h5py.File(cnmf_file)['estimates']['C']\n",
    "\n",
    "#convert it in a dataframe\n",
    "fluo_hdf=pd.DataFrame(fluo_hdf)\n",
    "\n",
    "\n",
    "#opening the stripe folder\n",
    "stripe_hdf=h5py.File(belt_file)['inferred']['belt_dict']['stripes']\n",
    "stripe_hdf=pd.DataFrame(stripe_hdf)\n",
    "fluo_hdf_r=fluo_hdf.T #swap columns and rows in fluo hdf\n",
    "n_cells=fluo_hdf_r.shape[1]\n",
    "\n",
    "#normazing the whole panda frame by applying z score as well as keeping the raw data for visualization\n",
    "raw_data=fluo_hdf_r\n",
    "fluo_hdf_r=fluo_hdf_r.apply(zscore,axis=0)\n",
    "\n",
    "#identifying and storing the number of units\n",
    "units_n=fluo_hdf_r.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.creating panda frames for running distance, speed, time and immobility\n",
    "2.adding all of them into the intial panda frame so that I can analyze everything at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluo_z_score,fluo_raw_data= adding_parameters(fluo_hdf_r,raw_data,belt_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to plot as I test the different distances every time in every round to compare.\n",
    "all the rounds should be approximately 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_distance=belt_length*10\n",
    "n_rounds=int(fluo_z_score['Rounds'].max())\n",
    "rounds=[]\n",
    "for round in range(1,n_rounds+1):\n",
    "    dis=fluo_z_score[fluo_z_score['Rounds']==round].iloc[-1]['Distance']\n",
    "    if abs(dis-wanted_distance)<15:\n",
    "        rounds.append(round)\n",
    "\n",
    "num_rounds=len(rounds)\n",
    "print(f'Rounds: {rounds}\\n Number of rounds: {num_rounds}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "with h5py.File(f'{save_folder}/output_info.h5', 'w') as file:\n",
    "    file.create_dataset('rounds', data=rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=fluo_z_score                    #renaming data so that it is easier to process them\n",
    "data=data[data['Speed']>0]   #taking only the timepoints when the mouse moves\n",
    "data=data[data['Rounds'].isin(rounds)]         #only taking the data of 8 rounds because this is where the belt approximates 150 cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate spatial firing map for each round indivudually. then I can average them easily.\n",
    "no need to do it from the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns\n",
    "fluorescence_traces = data.iloc[:, :units_n]  # Columns containing fluorescence traces\n",
    "distance = data['Distance']  # Column containing distance on the linear belt\n",
    "speed = data['Speed']   # Column containing speed\n",
    "running = data['Running'] # Column containing running status\n",
    "\n",
    "\n",
    "num_units=units_n\n",
    "\n",
    "#making the firing rate map for every cell and every round for both zscore and raw data\n",
    "\n",
    "firing_rate_maps=make_firing_rate_maps(fluo_z_score,rounds,num_units,num_bins)\n",
    "firing_rate_maps_raw_data=make_firing_rate_maps(fluo_raw_data,rounds,num_units,num_bins)\n",
    "\n",
    "#calculate the average firing rate map for every cell\n",
    "\n",
    "avr_firing_rate_maps=np.mean(firing_rate_maps,axis=1)\n",
    "avr_firing_rate_maps_raw_data=np.mean(firing_rate_maps_raw_data,axis=1)\n",
    "\n",
    "#caclulate the event map for every cell\n",
    "#meaning I will make a binary array where every peak of the activity is 1 and everything else is zero\n",
    "\n",
    "events_per_cell=make_binary(firing_rate_maps,peak_threshold=3,peak_distance=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the data\n",
    "\n",
    "with h5py.File(f'{save_folder}/output_info.h5', 'a') as file:\n",
    "    file.create_dataset('number of units',data=units_n)\n",
    "    file.create_dataset('firing_rate_maps', data=firing_rate_maps)\n",
    "    file.create_dataset('events_per_cell', data=events_per_cell)\n",
    "    file.create_dataset('avr_firing_rate_maps', data=avr_firing_rate_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the units which have at least a certain amount of events\n",
    "\n",
    "cells_with_events=[]\n",
    "silent_cells=[]\n",
    "for i in range(units_n):\n",
    "    if np.sum(events_per_cell[i])>n_events_threshold:\n",
    "        cells_with_events.append(i)\n",
    "    else:\n",
    "        silent_cells.append(i)\n",
    "\n",
    "with h5py.File(f'{save_folder}/output_info.h5', 'a') as file:\n",
    "    file.create_dataset('cells_with_events', data=cells_with_events)\n",
    "    file.create_dataset('silent_cells',data=silent_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating kolmogorov smirnon analysis data for every cell so I do not do it inside the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting morphology of all cells\n",
    "\n",
    "spatial=cell_morphology(cnmf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting\n",
    "1. z score activity per round per cell\n",
    "2. average z-score activity for all the rounds\n",
    "3. spatial vector analysis schematic and histogram with comparison of shuffling data\n",
    "4. statistical significanc e analysis using colmogorov-smirnov test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for plotting everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_folder=f'{save_folder}'\n",
    "if not os.path.exists(fig_folder):\n",
    "    os.makedirs(fig_folder)\n",
    "\n",
    "\n",
    "#creating pdfs for significant and non significant cells sop that I can review them after\n",
    "# Create two pdf files\n",
    "significant_cells = PdfPages(f'{fig_folder}/{mouse_ID}_{condition}_significant_place_cells.pdf')\n",
    "non_significant_cells = PdfPages(f'{fig_folder}/{mouse_ID}_{condition}_non_significant_place_cells.pdf')\n",
    "\n",
    "\n",
    "angles = np.linspace(0, 2*np.pi, num_bins, endpoint=False) #initializing the circle with 150 bins corresponding to the distance on the belt\n",
    "\n",
    "place_cells_both_methods=[]\n",
    "place_cells_tuned_vector=[]\n",
    "place_cells_ks_test=[]\n",
    "\n",
    "non_place_cells_tuned_vector=[]\n",
    "\n",
    "for cell in cells_with_events:\n",
    "    \n",
    "    data=firing_rate_maps[cell]\n",
    "    data_avg=avr_firing_rate_maps[cell]\n",
    "\n",
    "    events_data = events_per_cell[cell]  # Assuming you have your actual events data\n",
    "    peak_n=np.sum(events_data) #finding the number of peaks during the whole time the mouse was running\n",
    "\n",
    "    ####################################################\n",
    "    # creating the plot where I will put all of the suplots inside\n",
    "    ###################################################\n",
    "\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(15, 15))\n",
    "    fig.suptitle(f'Cell {cell} \\n shuffles {shuffling_times}')\n",
    "\n",
    "    ###################################################\n",
    "    #plotting fluorescence for every round in the first subplot\n",
    "    ##################################################\n",
    "\n",
    "    sns.heatmap(data,ax=ax[0,0],cbar_kws={'label': 'z-score fluorescence'})\n",
    "    ax[0,0].set_ylabel('Rounds')\n",
    "    ax[0,0].set_title(\"Activity per round\")\n",
    "    ax[0,0].set_xlabel('Position belt (cm)')\n",
    "    ax1_labels=range(1,num_rounds+1)\n",
    "    ax[0,0].set_yticklabels(ax1_labels)\n",
    "    custom_ticks = [0, 50, 100, 150]  # Specify the positions where you want the ticks\n",
    "    custom_labels = ['0', '50', '100', '150']  # Specify the labels for the ticks\n",
    "    ax[0,0].set_xticks(custom_ticks)\n",
    "    ax[0,0].set_xticklabels(custom_labels)\n",
    "\n",
    "    ###################################################\n",
    "    #plotting average z=score for every round in the second subplot\n",
    "    ##################################################\n",
    "\n",
    "\n",
    "    avg_activity = pd.DataFrame(data_avg, columns=['']) #taking the average activity of the cell and converting it to data frame to plot it\n",
    "    sns.heatmap(avg_activity.transpose(),ax=ax[0,1],cbar_kws={'label': 'z-score fluorescence'})\n",
    "\n",
    "    #changing the size of the second subplot\n",
    "    #position = ax[0,1].get_position()  # Get the current position of the subplot\n",
    "    ax[0,1].set_title(\"Average activity\")\n",
    "    #position.y0 -= -0.1  # Decrease the bottom boundary\n",
    "    #position.y1 *= 0.9  # Decrease the height\n",
    "    #ax[0,1].set_position(position)  # Set the new position\n",
    "    ax[0,1].set_ylabel('')\n",
    "    ax[0,1].set_xlabel('Position belt (cm)')\n",
    "    ax[0,1].set_xticks(custom_ticks)\n",
    "    ax[0,1].set_xticklabels(custom_labels)\n",
    "\n",
    "    ###################################################\n",
    "    #plotting spatial tuned vector figure\n",
    "    ##################################################\n",
    "\n",
    "\n",
    "    # Create a polar plot with circles representing each round\n",
    "    \n",
    "    ax[1,0] = plt.subplot(2,2,3,projection='polar')\n",
    "    ax[1,0].set_theta_direction(-1)  # Set clockwise direction\n",
    "    ax[1,0].set_theta_zero_location('N')  # Set zero angle at North\n",
    "\n",
    "    # Customize the tick labels on the circles (bins) so  that I can see the distance on the belt instead of degrees\n",
    "    circle_ticks = [0, 120, 240]  # Tick positions in degrees\n",
    "    circle_labels = ['0/150 cm', '50 cm', '100 cm']  # Labels for the ticks\n",
    "    ax[1,0].set_xticks(np.radians(circle_ticks))  # Set the tick positions in radians\n",
    "    ax[1,0].set_xticklabels(circle_labels)  # Set the tick labels\n",
    "\n",
    "    # Plot events on the circle\n",
    "    for i, events_round in enumerate(events_data):\n",
    "        event_angles = angles[np.where(events_round == 1)] #I found the angles where I have events\n",
    "        event_radii = np.ones_like(event_angles) * (i + 1)  # Adjust the radius for each round\n",
    "        ax[1,0].scatter(event_angles, event_radii, s=100, label=f'Round {i+1}', alpha=0.7)\n",
    "        for angle, radius in zip(event_angles, event_radii):\n",
    "            ax[1,0].plot([0, angle], [0, radius], color='black', linestyle='-', linewidth=1)  # Connect center to event dot. better for visualization\n",
    "\n",
    "    # Calculate average direction using Cartesian coordinates\n",
    "    x_coords,y_coords=TunedVector.calculate_coordinates(data=events_data,angles=angles)\n",
    "\n",
    "    #finding sum coordinates and direction\n",
    "    sum_direction,sum_magnitude=TunedVector.calculate_avr_vector(x_coords,y_coords,peak_n)\n",
    "\n",
    "    # Plot the average tuning vector as an arrow\n",
    "    ax[1,0].arrow(0, 0, sum_direction, sum_magnitude, head_width=0, head_length=0,linewidth=4, fc='red', ec='red')\n",
    "\n",
    "    # Customize plot\n",
    "    ax[1,0].set_title(f'Events and Tuning Vectors Cell {cell}')\n",
    "    ax[1,0].legend(loc='upper left',bbox_to_anchor=(0.9, 1), frameon=False)\n",
    "    ax[1,0].grid(True)\n",
    "\n",
    "    # Convert average direction from radians to degrees\n",
    "    sum_direction_degrees = np.degrees(sum_direction)\n",
    "    # Map the sum direction to the corresponding position on the belt\n",
    "    position_on_belt = (sum_direction_degrees % 360) * (belt_length / 360)\n",
    "\n",
    "    ###########\n",
    "    #plotting the histogram of the vector lengths coming from the shuffled data and compare it with the actual vector length\n",
    "    ###########\n",
    "\n",
    "    shuffled_vector_lengths=[]\n",
    "\n",
    "    for n in range(shuffling_times):\n",
    "        #shuffling every row separately\n",
    "        shuffled_events_data = events_data.copy()  # Make a copy to avoid modifying original data\n",
    "        for row in shuffled_events_data:\n",
    "            np.random.shuffle(row)  # Shuffle the spiking events within each round independently\n",
    "\n",
    "        # Calculate average direction and magnitude for shuffled data. same logic as before exactly\n",
    "        shuffled_x_coords,shuffled_y_coords=TunedVector.calculate_coordinates(data=shuffled_events_data,angles=angles)\n",
    "        shuffled_sum_direction,shuffled_sum_magnitude=TunedVector.calculate_avr_vector(shuffled_x_coords,shuffled_y_coords,peak_n)\n",
    "        shuffled_vector_lengths.append(shuffled_sum_magnitude)\n",
    "\n",
    "        # Map the shuffled average direction to the corresponding position on the belt\n",
    "        shuffled_position_on_belt = (np.degrees(shuffled_sum_direction) % 360) * (belt_length / 360)\n",
    "\n",
    "\n",
    "    ###########\n",
    "    #making the histogram with the shuffled data and our actual vector length\n",
    "    ###########\n",
    "\n",
    "    # Calculate histogram\n",
    "    counts, bins = np.histogram(shuffled_vector_lengths, bins=20)\n",
    "\n",
    "    # Calculate probabilities\n",
    "    total_samples = len(shuffled_vector_lengths)\n",
    "    probabilities = counts / total_samples\n",
    "\n",
    "    # Plot histogram with probabilities\n",
    "    ax[1,1].bar(bins[:-1], probabilities, width=np.diff(bins), color='blue', alpha=0.7)\n",
    "    ax[1,1].axvline(x=sum_magnitude,color='red')\n",
    "    ax[1,1].set_xlabel('Vector Length')\n",
    "    ax[1,1].set_ylabel('Probability')\n",
    "    # Remove right and upper axes\n",
    "    ax[1,1].spines['right'].set_visible(False)\n",
    "    ax[1,1].spines['top'].set_visible(False)\n",
    "    ax[1,1].set_title('Histogram for vector lengths')\n",
    "    ax[1,1].grid(False)\n",
    "\n",
    "\n",
    "    # comparing it with the actual vector lenth now)\n",
    "    # Actual vector length\n",
    "    actual_length = sum_magnitude  # Example value\n",
    "\n",
    "\n",
    "    # Calculate the p-value\n",
    "    larger_lengths_count = np.sum(np.array(shuffled_vector_lengths) > actual_length)\n",
    "    total_samples = len(shuffled_vector_lengths)\n",
    "    p_value_vector = larger_lengths_count / total_samples\n",
    "    # Annotate the p-value on the upper side of the plot\n",
    "\n",
    "    # Create a legend entry with the p-value\n",
    "    p_value_text = f'P-value: {p_value_vector:.4f}'\n",
    "    p_value_patch = mpatches.Patch(color='none', label=p_value_text)\n",
    "\n",
    "    # Add the legend with the custom entry\n",
    "    #ax[1,1].legend(handles=[p_value_patch],loc='upper right', bbox_to_anchor=(1.25, 1.05),frameon=False)\n",
    "\n",
    "    ###################################################\n",
    "    #plotting the histogram from colmogorov smirnov test\n",
    "    ##################################################\n",
    "\n",
    "\n",
    "    ###########################\n",
    "    # I will shuffle once. and then I will compare the shufle data with my original data. the colmogorov smiron value will be the value that I will compare later\n",
    "    # later I will shuffle the data 1000 times and I will compare them to the first suffling data\n",
    "    ##############################\n",
    "\n",
    "    shuffled_ks=[] #array where I will put the ks distances where I will compare the shuffled data with my first shuffling\n",
    "   \n",
    "    #shuffling for the baseline\n",
    "    baseline_avg=KstestPlaceCells.ks_shuffling(data,num_rounds=num_rounds,shuf_distance=belt_length)\n",
    "    \n",
    "    baseline_ks,_=kstest(data_avg,baseline_avg)\n",
    "\n",
    "    for n in range(1,shuffling_times):\n",
    "        shuffle_avg=KstestPlaceCells.ks_shuffling(data,num_rounds=num_rounds,shuf_distance=belt_length)\n",
    "        ks_shuffle,p_value=kstest(baseline_avg,shuffle_avg)\n",
    "        shuffled_ks.append(ks_shuffle)\n",
    "\n",
    "    \n",
    "    # Calculate histogram\n",
    "    counts, bins = np.histogram(shuffled_ks, bins=30)\n",
    "\n",
    "    # Calculate probabilities\n",
    "    total_samples = len(shuffled_ks)\n",
    "    probabilities = counts / total_samples\n",
    "    # Calculate the p-value\n",
    "    larger_lengths_count = np.sum(np.array(shuffled_ks) > baseline_ks)\n",
    "    p_value_ks = larger_lengths_count / total_samples\n",
    "    # Annotate the p-value on the upper side of the plot\n",
    "    # Create a legend entry with the p-value\n",
    "    p_value_text = f'P-value: {p_value_ks:.4f}'\n",
    "    p_value_patch = mpatches.Patch(color='none', label=p_value_text)\n",
    "\n",
    "    # Add the legend with the custom entry\n",
    "    ax[2,1].legend(handles=[p_value_patch],loc='upper right', bbox_to_anchor=(1.25, 1.05),frameon=False)\n",
    "\n",
    "    ax[2,1].bar(bins[:-1], probabilities, width=np.diff(bins), color='blue', alpha=0.7)\n",
    "    ax[2,1].axvline(x=baseline_ks,color='red')\n",
    "    ax[2,1].set_xlabel('ks Length')\n",
    "    ax[2,1].set_ylabel('Probability')\n",
    "    # Remove right and upper axes\n",
    "    ax[2,1].spines['right'].set_visible(False)\n",
    "    ax[2,1].spines['top'].set_visible(False)\n",
    "    ax[2,1].set_title('colmogorov smirnov test')\n",
    "    ax[2,1].grid(False)\n",
    "\n",
    "    if p_value_vector < 0.05:\n",
    "        place_cells_tuned_vector.append(cell)\n",
    "    elif p_value_vector>=0.05:\n",
    "        non_place_cells_tuned_vector.append(cell)\n",
    "\n",
    "    if p_value_ks < 0.05:\n",
    "        place_cells_ks_test.append(cell)\n",
    "\n",
    "        # Check the p-value and save the figure to the appropriate PDF file\n",
    "    if p_value_vector < 0.05 and p_value_ks < 0.05:\n",
    "        place_cells_both_methods.append(cell)\n",
    "        significant_cells.savefig(fig)\n",
    "    else:\n",
    "        non_significant_cells.savefig(fig)\n",
    "\n",
    "    plt.ioff() #this is so I dont have to show the plots but only store them\n",
    "    plt.close()\n",
    "\n",
    "# Close the PDF files after saving all figures\n",
    "significant_cells.close()\n",
    "non_significant_cells.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f'{save_folder}/output_info.h5', 'a') as file:\n",
    "    file.create_dataset('place_cell_both_methods', data=place_cells_both_methods)\n",
    "    file.create_dataset('place_cells_tuned_vector', data=place_cells_tuned_vector)\n",
    "    file.create_dataset('place_cells_ks_test', data=place_cells_ks_test)\n",
    "    file.create_dataset('non_place_cells_tuned_vector',data=non_place_cells_tuned_vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for plotting everyting including calcium traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #INITIAL PARAMETERS\n",
    "\n",
    "\n",
    "# n_cells=units_n #number of cells that I want to permutate\n",
    "# peak_threshold=input_info[\"peak_threshold\"]  #amount of sd from the baseline activity\n",
    "# peak_distance=input_info[\"peak_distance\"]  #distance in cells that I am looking for local maxima\n",
    "# belt_length=input_info[\"belt_length\"] #(in cm)\n",
    "# shuffling_times=input_info[\"shuffling_times\"]  #time of shuffling for statistical comparison\n",
    "\n",
    "# #storing round info to jason\n",
    "# peak_parameters_info= {\n",
    "#     \"threshold\":peak_threshold,\n",
    "#     \"peak distance (moving window for peaks)\":peak_distance\n",
    "# }\n",
    "\n",
    "# mouse_info.update(peak_parameters_info)\n",
    "# with open(jason_path, \"w\") as json_file:\n",
    "#     json.dump(mouse_info, json_file,indent=jason_indent)\n",
    "\n",
    "\n",
    "\n",
    "# #creating pdfs for significant and non significant cells sop that I can review them after\n",
    "# # Create two pdf files\n",
    "# # significant_cells = PdfPages(results_folder+'significant_place_cells.pdf')\n",
    "# # non_significant_cells = PdfPages(results_folder+'non_significant_place_cells.pdf')\n",
    "\n",
    "\n",
    "# angles = np.linspace(0, 2*np.pi, num_bins, endpoint=False) #initializing the circle with 150 bins corresponding to the distance on the belt\n",
    "\n",
    "# place_cells_both_methods=[]\n",
    "# place_cells_tuned_vector=[]\n",
    "# place_cells_ks_test=[]\n",
    "\n",
    "\n",
    "\n",
    "# for cell in cells_with_events[:5]:\n",
    "    \n",
    "#     data=firing_rate_maps[cell]\n",
    "#     events_data = events_per_cell[cell]  # Assuming you have your actual events data\n",
    "    \n",
    "#     peak_n=np.sum(events_data) #finding the number of peaks during the whole time the mouse was running\n",
    "\n",
    "#     ####################################################\n",
    "#     # creating the plot where I will put all of the suplots inside\n",
    "#     ###################################################\n",
    "\n",
    "#     fig, ax = plt.subplots(5, 2, figsize=(20, 20))\n",
    "#     plt.subplots_adjust(hspace=0.4,wspace=0.2)\n",
    "#     fig.suptitle(f'Cell {cell} \\n shuffles {shuffling_times}')\n",
    "\n",
    "   \n",
    "#     import placecode.plots as placecode_plots\n",
    "\n",
    "\n",
    "#     placecode_plots.plot_fluorescence_per_round(\n",
    "#         binned_rounds=firing_rate_maps_raw_data[cell], \n",
    "#         ax=ax[0,0],\n",
    "#     )\n",
    "\n",
    "#     placecode_plots.plot_average_raw_fluorescence(\n",
    "#         data=avr_firing_rate_maps_raw_data[cell], \n",
    "#         ax=ax[0,1]\n",
    "#     )\n",
    "\n",
    "#     placecode_plots.plot_zscore_fluorescence_per_round(\n",
    "#         data=firing_rate_maps[cell],\n",
    "#         ax=ax[1,0])\n",
    "    \n",
    "\n",
    "#     data_avg=avr_firing_rate_maps[cell]\n",
    "#     placecode_plots.plot_average_zscore_activity(\n",
    "#         data=data_avg,\n",
    "#         ax=ax[1,1])\n",
    "\n",
    "#     ###################################################\n",
    "#     #plotting spatial tuned vector figure\n",
    "#     ##################################################\n",
    "\n",
    "\n",
    "#     # Create a polar plot with circles representing each round\n",
    "    \n",
    "#     ax[2,0] = plt.subplot(2,2,3,projection='polar')\n",
    "#     ax[2,0] .set_theta_direction(-1)  # Set clockwise direction\n",
    "#     ax[2,0] .set_theta_zero_location('N')  # Set zero angle at North\n",
    "\n",
    "#     # Customize the tick labels on the circles (bins) so  that I can see the distance on the belt instead of degrees\n",
    "#     circle_ticks = [0, 120, 240]  # Tick positions in degrees\n",
    "#     circle_labels = ['0/150 cm', '50 cm', '100 cm']  # Labels for the ticks\n",
    "#     ax[2,0].set_xticks(np.radians(circle_ticks))  # Set the tick positions in radians\n",
    "#     ax[2,0].set_xticklabels(circle_labels)  # Set the tick labels\n",
    "\n",
    "#     # Plot events on the circle\n",
    "#     for i, events_round in enumerate(events_data):\n",
    "#         event_angles = angles[np.where(events_round == 1)] #I found the angles where I have events\n",
    "#         event_radii = np.ones_like(event_angles) * (i + 1)  # Adjust the radius for each round\n",
    "#         ax[2,0].scatter(event_angles, event_radii, s=100, label=f'Round {i+1}', alpha=0.7)\n",
    "#         for angle, radius in zip(event_angles, event_radii):\n",
    "#             ax[2,0] .plot([0, angle], [0, radius], color='black', linestyle='-', linewidth=1)  # Connect center to event dot. better for visualization\n",
    "\n",
    "#     # Calculate average direction using Cartesian coordinates\n",
    "#     x_coords = []\n",
    "#     y_coords = []\n",
    "#     for i, events_round in enumerate(events_data):\n",
    "#         event_angles = angles[np.where(events_round == 1)]\n",
    "#         event_radii = np.ones_like(event_angles) * (i + 1)  # Adjust the radius for each round\n",
    "#         x_coords.extend(np.cos(event_angles)/(i + 1))\n",
    "#         y_coords.extend(np.sin(event_angles)/(i + 1))\n",
    "\n",
    "#     # Sum the coordinates . I divide it with number of events. instead of number of rounds MAYBE THIS WOULD NEED TO CHANGE\n",
    "#     sum_x = np.sum(x_coords)/ peak_n\n",
    "#     sum_y = np.sum(y_coords)/ peak_n\n",
    "\n",
    "#     # Convert the sum of coordinates to polar coordinates\n",
    "#     sum_direction = np.arctan2(sum_y, sum_x)  # Note: y comes before x in arctan2\n",
    "#     sum_magnitude = np.sqrt(sum_x**2 + sum_y**2)\n",
    "\n",
    "#     # Plot the average tuning vector as an arrow\n",
    "#     ax[2,0].arrow(0, 0, sum_direction, sum_magnitude, head_width=0, head_length=0,linewidth=4, fc='red', ec='red')\n",
    "\n",
    "#     # Customize plot\n",
    "#     ax[2,0].set_title(f'Events and Tuning Vectors Cell {cell}')\n",
    "#     ax[2,0].legend(loc='upper left',bbox_to_anchor=(0.9, 1), frameon=False)\n",
    "#     ax[2,0].grid(True)\n",
    "\n",
    "#     # Convert average direction from radians to degrees\n",
    "#     sum_direction_degrees = np.degrees(sum_direction)\n",
    "#     # Map the sum direction to the corresponding position on the belt\n",
    "#     position_on_belt = (sum_direction_degrees % 360) * (belt_length / 360)\n",
    "\n",
    "#     ###########\n",
    "#     #plotting the histogram of the vector lengths coming from the shuffled data and compare it with the actual vector length\n",
    "#     ###########\n",
    "\n",
    "#     shuffled_vector_lengths=[]\n",
    "\n",
    "#     for n in range(shuffling_times):\n",
    "#         #shuffling every row separately\n",
    "#         shuffled_events_data = events_data.copy()  # Make a copy to avoid modifying original data\n",
    "#         for row in shuffled_events_data:\n",
    "#             np.random.shuffle(row)  # Shuffle the spiking events within each round independently\n",
    "\n",
    "#         # Calculate average direction and magnitude for shuffled data. same logic as before exactly\n",
    "#         shuffled_x_coords = []\n",
    "#         shuffled_y_coords = []\n",
    "#         for i, events_round in enumerate(shuffled_events_data):\n",
    "#             event_angles = angles[np.where(events_round == 1)]\n",
    "#             event_radii = np.ones_like(event_angles) * (i + 1)  # Adjust the radius for each round\n",
    "#             shuffled_x_coords.extend(np.cos(event_angles)/(i + 1))\n",
    "#             shuffled_y_coords.extend(np.sin(event_angles)/(i + 1))\n",
    "\n",
    "#         shuffled_sum_x = np.sum(shuffled_x_coords)/ peak_n\n",
    "#         shuffled_sum_y = np.sum(shuffled_y_coords)/ peak_n\n",
    "#         shuffled_sum_direction = np.arctan2(shuffled_sum_y, shuffled_sum_x)\n",
    "#         shuffled_sum_magnitude = np.sqrt(shuffled_sum_x**2 + shuffled_sum_y**2)\n",
    "#         shuffled_vector_lengths.append(shuffled_sum_magnitude)\n",
    "\n",
    "#         # Map the shuffled average direction to the corresponding position on the belt\n",
    "#         shuffled_position_on_belt = (np.degrees(shuffled_sum_direction) % 360) * (150 / 360)\n",
    "\n",
    "\n",
    "#     ###########\n",
    "#     #making the histogram with the shuffled data and our actual vector length\n",
    "#     ###########\n",
    "\n",
    "#     # Calculate histogram\n",
    "#     counts, bins = np.histogram(shuffled_vector_lengths, bins=20)\n",
    "\n",
    "#     # Calculate probabilities\n",
    "#     total_samples = len(shuffled_vector_lengths)\n",
    "#     probabilities = counts / total_samples\n",
    "\n",
    "#     # comparing it with the actual vector lenth now)\n",
    "#     # Actual vector length\n",
    "#     actual_length = sum_magnitude  # Example value\n",
    "\n",
    "\n",
    "#     # Calculate the p-value\n",
    "#     larger_lengths_count = np.sum(np.array(shuffled_vector_lengths) > actual_length)\n",
    "#     total_samples = len(shuffled_vector_lengths)\n",
    "#     p_value_vector = larger_lengths_count / total_samples\n",
    "\n",
    "#     # Plot histogram with probabilities\n",
    "#     ax[2,1].bar(bins[:-1], probabilities, width=np.diff(bins), color='blue', alpha=0.7)\n",
    "#     ax[2,1].axvline(x=sum_magnitude,color='red')\n",
    "#     ax[2,1].set_xlabel('Vector Length')\n",
    "#     ax[2,1].set_ylabel('Probability')\n",
    "#     # Remove right and upper axes\n",
    "#     ax[2,1].spines['right'].set_visible(False)\n",
    "#     ax[2,1].spines['top'].set_visible(False)\n",
    "#     ax[2,1].set_title(f'Histogram for vector lengths\\np-value:{p_value_vector:.4f}')\n",
    "#     ax[2,1].grid(False)\n",
    "\n",
    "#     ###################################################\n",
    "#     #plotting the histogram from colmogorov smirnov test\n",
    "#     ##################################################\n",
    "\n",
    "#     ###########################\n",
    "#     # I will shuffle once. and then I will compare the shufle data with my original data. the colmogorov smiron value will be the value that I will compare later\n",
    "#     # later I will shuffle the data 1000 times and I will compare them to the first suffling data\n",
    "#     ##############################\n",
    "\n",
    "#     shuffled_ks=[] #array where I will put the ks distances where I will compare the shuffled data with my first shuffling\n",
    "#     baseline=data.copy()\n",
    "\n",
    "#     #shuffle 1 for the baseline\n",
    "#     for i in range(num_rounds):\n",
    "#         shuf=random.randint(1,150)\n",
    "#         baseline[i]=np.roll(baseline[i],shuf)\n",
    "#     baseline_avg=np.mean(baseline,axis=0)\n",
    "    \n",
    "#     baseline_ks,_=kstest(data_avg,baseline_avg)\n",
    "\n",
    "\n",
    "#     # now I will shuffle many times and then compare\n",
    "        \n",
    "#     for n in range(1,shuffling_times):\n",
    "#         data_shuffle=data.copy()    \n",
    "#         for i in range(num_rounds):\n",
    "#             shuf=random.randint(1,150)\n",
    "#             data_shuffle[i]=np.roll(data_shuffle[i],shuf)\n",
    "        \n",
    "        \n",
    "\n",
    "#         data_shuffle=np.mean(data_shuffle,axis=0)\n",
    "#         ks_shuffle,p_value_=kstest(baseline_avg,data_shuffle)\n",
    "#         shuffled_ks.append(ks_shuffle)\n",
    "\n",
    "    \n",
    "#     # Calculate histogram\n",
    "#     counts, bins = np.histogram(shuffled_ks, bins=30)\n",
    "\n",
    "#     # Calculate probabilities\n",
    "#     total_samples = len(shuffled_ks)\n",
    "#     probabilities = counts / total_samples\n",
    "#     # Calculate the p-value\n",
    "#     larger_lengths_count = np.sum(np.array(shuffled_ks) > baseline_ks)\n",
    "#     p_value_ks = larger_lengths_count / total_samples\n",
    "#     # Annotate the p-value on the upper side of the plot\n",
    "#     # Create a legend entry with the p-value\n",
    "#     p_value_text = f'P-value ks: {p_value_ks:.4f}'\n",
    "#     #p_value_patch = mpatches.Patch(color='none', label=p_value_text)\n",
    "\n",
    "#     # Add the legend with the custom entry\n",
    "#     ax[3,1].bar(bins[:-1], probabilities, width=np.diff(bins), color='blue', alpha=0.7)\n",
    "#     ax[3,1].axvline(x=baseline_ks,color='red')\n",
    "#     ax[3,1].set_xlabel('ks Length')\n",
    "#     ax[3,1].set_ylabel('Probability')\n",
    "#     # Remove right and upper axes\n",
    "#     ax[3,1].spines['right'].set_visible(False)\n",
    "#     ax[3,1].spines['top'].set_visible(False)\n",
    "#     ax[3,1].set_title(f'colmogorov smirnov test\\np-value:{p_value_ks:.4f}')\n",
    "#     ax[3,1].grid(False)\n",
    "\n",
    "#     if p_value_vector < 0.05:\n",
    "#         place_cells_tuned_vector.append(cell)\n",
    "#     if p_value_ks < 0.05:\n",
    "#         place_cells_ks_test.append(cell)\n",
    "\n",
    "#     #ax[4,0]=None\n",
    "\n",
    "#     #plotting cells morphology\n",
    "\n",
    "#     cell_shape = np.reshape(spatial[:,cell], (512, 512)) # (262144 -> 512x512, i.e. \"unflatten\")\n",
    "#     indices=np.where(cell_shape>0)\n",
    "\n",
    "#     v_viz=40 #value for better visualization\n",
    "\n",
    "#     #filtered=gaussian_filter(spatial,sigma=-1)\n",
    "\n",
    "#     # Determine minimum and maximum row and column indices\n",
    "#     min_row, max_row = np.min(indices[0]), np.max(indices[0])\n",
    "#     min_col, max_col = np.min(indices[1]), np.max(indices[1])\n",
    "\n",
    "#     # Extract the sub-array corresponding to the area where the cell appears\n",
    "#     viz_values=np.array([min_row-v_viz,max_row+1+v_viz,min_col-v_viz,max_col+1+v_viz])\n",
    "#     # Replace any value less than zero with zero\n",
    "#     viz_values[viz_values < 0] = 0\n",
    "\n",
    "#     sub_data = cell_shape[viz_values[0]:viz_values[1], viz_values[2]:viz_values[3]]\n",
    "\n",
    "#     # Plot the sub-array using Seaborn's heatmap\n",
    "\n",
    "#     sns.heatmap(sub_data, cmap='viridis',cbar=False,ax=ax[4,1])\n",
    "#     ax[4,1].set_xticks([])\n",
    "#     ax[4,1].set_yticks([])\n",
    "#     ax[4,1].set_title(f'Cell Morphology')\n",
    "\n",
    "#     ax[4,0].axis('off')\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "#     plt.subplots_adjust(hspace=0.8,wspace=0.2)\n",
    "#     #plt.subplots_adjust(wspace=1)\n",
    "\n",
    "\n",
    "#     #     # Check the p-value and save the figure to the appropriate PDF file\n",
    "#     # if p_value_vector < 0.05 and p_value_ks < 0.05:\n",
    "#     #     place_cells_both_methods.append(cell)\n",
    "#     #     significant_cells.savefig(fig)\n",
    "#     # else:\n",
    "#     #     non_significant_cells.savefig(fig)\n",
    "    \n",
    "#     plt.ioff() #this is so I dont have to show the plots but only store them\n",
    "\n",
    "#     #plt.close()\n",
    "\n",
    "# # Close the PDF files after saving all figures\n",
    "# # significant_cells.close()\n",
    "# # non_significant_cells.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating the plae code diagram for both methods colmogorov smiron and tuned vector analysis separatately\n",
    "I do this with the zscore fluorescence and raw data at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avr_firing_rate_maps_df=pd.DataFrame(avr_firing_rate_maps) #converting the whole units array into a panda frame\n",
    "avr_firing_rate_maps_raw_data_df=pd.DataFrame(avr_firing_rate_maps_raw_data) #converting the whole units array into a panda frame\n",
    "\n",
    "place_cells_plotting=PdfPages(fig_folder+'/place_cell_coding_zscore.pdf')\n",
    "\n",
    "\n",
    "cell_datasets=[place_cells_both_methods,place_cells_tuned_vector,place_cells_ks_test]\n",
    "titles=['both methods','tuned vector','ks test']\n",
    "\n",
    "custom_ticks = [0, 50, 100, 150]  # Specify the positions where you want the ticks\n",
    "custom_labels = ['0', '50', '100', '150']  # Specify the labels for the ticks\n",
    "\n",
    "fig2,ax=plt.subplots(1,3,figsize=(15,10))#\n",
    "fig2.suptitle(f'{mouse_ID}\\n{condition}\\n Zscore fluorescence')\n",
    "\n",
    "\n",
    "#########################################\n",
    "# for zscore fluorescence\n",
    "############################################\n",
    "\n",
    "for i,(cell_dataset,ind_title) in enumerate(zip(cell_datasets,titles)):\n",
    "    place_cell_activity=avr_firing_rate_maps_df.iloc[cell_dataset] #keeping only the place but without changing the indexing\n",
    "    place_cell_indexes_max=np.argmax(place_cell_activity,axis=1) #finding the place of the max activity of every cell\n",
    "    place_cell_indexed_filtered=place_cell_activity.apply(np.argmax, axis=1).sort_values().index #there are the new indexes of the place cells just so thez can form the nice place cell diagram\n",
    "    original=place_cell_activity.index\n",
    "    transpose=place_cell_indexed_filtered\n",
    "    place_cell_activity=place_cell_activity.reindex(index=transpose) #reindexing the place cell panda frame according to the max activitz and the position in the belt\n",
    "    with h5py.File(f'{save_folder}/output_info.h5', 'a') as file:\n",
    "        # if f'sorted_place_cells_{ind_title}' in file:\n",
    "        #     del file[f'sorted_place_cells_{ind_title}']  # Delete the existing dataset\n",
    "        file.create_dataset(f'sorted_place_cells_{ind_title}', data=place_cell_activity)\n",
    "\n",
    "    sns.heatmap(place_cell_activity,ax=ax[i],vmin=0,cmap='viridis',cbar_kws={'label': 'z-score fluorescence'})\n",
    "    ax[i].set_xlabel('')\n",
    "    ax[i].set_ylabel('Place cells')    \n",
    "    ax[i].set_title(f'{ind_title}\\n{len(cell_dataset)} place cells')\n",
    "    ax[i].set_xticks(custom_ticks)\n",
    "    ax[i].set_yticks([])\n",
    "    ax[i].set_xticklabels(custom_labels)\n",
    "\n",
    "# #########################################\n",
    "# # for raw fluorescence\n",
    "# ############################################\n",
    "\n",
    "# for i,(cell_dataset,ind_title) in enumerate(zip(cell_datasets,titles)):\n",
    "#     place_cell_activity=avr_firing_rate_maps_raw_data_df.iloc[cell_dataset] #keeping only the place but without changing the indexing\n",
    "#     place_cell_indexes_max=np.argmax(place_cell_activity,axis=1) #finding the place of the max activity of every cell\n",
    "#     place_cell_indexed_filtered=place_cell_activity.apply(np.argmax, axis=1).sort_values().index #there are the new indexes of the place cells just so thez can form the nice place cell diagram\n",
    "#     original=place_cell_activity.index\n",
    "#     transpose=place_cell_indexed_filtered\n",
    "#     place_cell_activity=place_cell_activity.reindex(index=transpose) #reindexing the place cell panda frame according to the max activitz and the position in the belt\n",
    "\n",
    "#     sns.heatmap(place_cell_activity,ax=ax[1,i],vmin=0,vmax=200,cmap='viridis',cbar_kws={'label': 'raw fluorescence'})\n",
    "#     ax[1,i].set_xlabel('Distance in belt (cm)')\n",
    "#     ax[1,i].set_ylabel('Place cells')    \n",
    "#     ax[1,i].set_title('')\n",
    "#     ax[1,i].set_xticks(custom_ticks)\n",
    "#     ax[1,i].set_yticks([])\n",
    "#     ax[1,i].set_xticklabels(custom_labels)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "place_cells_plotting.savefig(fig2)\n",
    "\n",
    "place_cells_plotting.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
