{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.stats import zscore,kstest\n",
    "import random\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import sys  # for importing one level above\n",
    "sys.path.append(\"..\")\n",
    "from placecode.spatial_coding_functions import firing_rate_map, read_spatial, make_binary, filter_event_count, vector_sum, spiking_rate_map\n",
    "from placecode.utils import open_file, open_dir\n",
    "from placecode.analysis_info import ExpInfo, AnalysisParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False  # flag whether to save results into hdf5 file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_expinfo = open_file(\"Select experiment info json file!\")\n",
    "exp_info = ExpInfo(fpath_expinfo)  # TODO: mount data folder! so we can access it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open analysis parameters, append mouse/session-specific data, save it later with results.\n",
    "fpath_analysis_params = open_file(\"Select analysis parameters json file!\")\n",
    "analysis_params = AnalysisParams(fpath_analysis_params)\n",
    "analysis_params.read_exp_info(exp_info)  # extract necessary experiment information for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the necessary files exist\n",
    "assert os.path.exists(exp_info.fpath_caim)\n",
    "assert os.path.exists(exp_info.fpath_loco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select folder to save results\n",
    "output_folder = open_dir(\"Select folder for output\")  \n",
    "# TODO: add output folder to analysis parameters? Create/check folder mouse_id -> condition, save results there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CaImAn data\n",
    "with h5py.File(exp_info.fpath_caim, \"r\") as hf_caim:\n",
    "    # temporal\n",
    "    temporal_raw=hf_caim['estimates']['C'][()]\n",
    "    n_components, n_frames = temporal_raw.shape\n",
    "    resolution = hf_caim[\"dims\"][()]\n",
    "    # access a single temporal component as temporal_raw[i]\n",
    "\n",
    "    # spatial\n",
    "    resolution = hf_caim[\"dims\"][()]\n",
    "    A_data = hf_caim[\"estimates\"][\"A\"][\"data\"][()]\n",
    "    A_indices = hf_caim[\"estimates\"][\"A\"][\"indices\"][()]\n",
    "    A_indptr = hf_caim[\"estimates\"][\"A\"][\"indptr\"][()]\n",
    "    A_shape = hf_caim[\"estimates\"][\"A\"][\"shape\"][()]\n",
    "    spatial = read_spatial(A_data, A_indices, A_indptr, A_shape, n_components, resolution, unflatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load loco data\n",
    "# TODO: include stripes, distance per round, etc. in loco data cut to scanner time frame. Missing in Martin's code?\n",
    "#   check https://github.com/mitlabence/matlab-2p/issues/11\n",
    "dict_loco = dict()\n",
    "with h5py.File(exp_info.fpath_loco, \"r\") as hf_loco:\n",
    "    for dset_name in hf_loco[\"inferred\"][\"belt_scn_dict\"].keys():\n",
    "        dtype = np.int16 if dset_name in [\"round\", \"rounds\", \"stripes\"] else np.float64\n",
    "        dict_loco[dset_name] = hf_loco[\"inferred\"][\"belt_scn_dict\"][dset_name][()].astype(dtype)\n",
    "print(dict_loco.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create z-score of temporal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_z = zscore(temporal_raw, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create binary trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_binary = np.zeros(shape=temporal_raw.shape, dtype=bool)\n",
    "for i_unit in range(n_components):\n",
    "    idx_peaks = find_peaks(temporal_raw[i_unit], height=analysis_params.peak_threshold, distance=analysis_params.peak_distance)[0]\n",
    "    temporal_binary[i_unit][idx_peaks] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter rounds\n",
    "Only use rounds where the total length adds up to the expected belt length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_distance=exp_info.belt_length_mm\n",
    "lv_rounds = dict_loco[\"rounds\"].copy()  \n",
    "lv_distPR = dict_loco[\"distance\"].copy() # belt_scn_dict hast distance per round as distance, see issue above\n",
    "lv_speed = dict_loco[\"speed\"].copy()\n",
    "n_rounds=lv_rounds.max()  # number of finished rounds\n",
    "rounds = []\n",
    "round_flags = np.zeros(n_rounds, dtype=np.int8)  # 1 if corresponding round included in analysis, 0 otherwise\n",
    "\n",
    "for round in range(1,n_rounds+1):\n",
    "    dist_current_round=lv_distPR[lv_rounds==round][-1]\n",
    "    #print(dist_current_round)\n",
    "    if abs(dist_current_round-expected_distance)<15:\n",
    "        rounds.append(round-1)\n",
    "        round_flags[round-1] = 1\n",
    "    else:\n",
    "        print(f\"Not using {round}\")\n",
    "\n",
    "\n",
    "num_rounds=len(rounds)\n",
    "print(f'Rounds (starting with 0): {rounds}\\n Number of rounds used: {num_rounds}, total {n_rounds}')\n",
    "\n",
    "# save as parameter a binary array on which round was included\n",
    "analysis_params.rounds_included = round_flags\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(temporal_binary, axis=1)  # number of firing events per neuron (unfiltered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter forward-locomoting frames\n",
    "Only use frames where mouse is running forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data\n",
    "included_rounds_frames =  np.isin(dict_loco[\"rounds\"], np.array(rounds) - 1)  # convert rounds to 0-indexing, filter to only those rounds that count\n",
    "loco_frames = dict_loco[\"speed\"] > 0\n",
    "idx_filtered = np.logical_and(included_rounds_frames, loco_frames)\n",
    "\n",
    "dict_loco_cut = dict()\n",
    "for k in dict_loco:\n",
    "    dict_loco_cut[k] = dict_loco[k][idx_filtered]\n",
    "temporal_raw_cut = temporal_raw[:, idx_filtered]\n",
    "temporal_z_cut = temporal_z[:, idx_filtered]\n",
    "temporal_binary_cut = temporal_binary[:, idx_filtered]\n",
    "rounds_cut = lv_rounds[idx_filtered]  # get corresponding round index\n",
    "distPR_cut = lv_distPR[idx_filtered]\n",
    "lv_speed_cut = lv_speed[idx_filtered]\n",
    "\n",
    "included_frames = np.arange(0, n_frames)\n",
    "included_frames_cut = included_frames[idx_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(temporal_binary_cut, axis=1)  # the firing events per cell used directly for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate spatial firing map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = analysis_params.n_bins\n",
    "n_units = n_components\n",
    "analysis_params.n_units = n_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_borders = np.linspace(0, analysis_params.belt_length_mm, analysis_params.n_bins, endpoint=True)\n",
    "#  get firing rate maps\n",
    "frm_raw = firing_rate_map(temporal_raw_cut, dict_loco_cut[\"rounds\"], dict_loco_cut[\"distance\"], n_bins)\n",
    "frm_z = firing_rate_map(temporal_z_cut, dict_loco_cut[\"rounds\"], dict_loco_cut[\"distance\"], n_bins)\n",
    "# average over rounds\n",
    "frm_raw_avg = np.mean(frm_raw, axis=1)\n",
    "frm_z_avg = np.mean(frm_z, axis=1)\n",
    "# calculate mean event map\n",
    "# new firing rate map method: use binary temporal components\n",
    "binary_spiking= spiking_rate_map(temporal_binary_cut, dict_loco_cut[\"rounds\"], dict_loco_cut[\"distance\"], n_bins) # make_binary(frm_raw,peak_threshold=analysis_params.peak_threshold,peak_distance=analysis_params.peak_distance)\n",
    "# apply minimum event count threshold to each cell, i.e. detect \"frequently firing\" cells\n",
    "# TODO: rename \"frequently firing\" cells to something better\n",
    "n_events_threshold = analysis_params.n_events_threshold\n",
    "i_cells_frequent_firing = filter_event_count(binary_spiking, n_events_threshold)\n",
    "# get a percent value of the \"frequently firing\" cells\n",
    "prc_frequent_firing_cells=100*len(i_cells_frequent_firing)/n_units\n",
    "# TODO: save indices of cells that get accepted in this step "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check processed data\n",
    "Plot locomotion (grey) and tmeporal component (green). Show frames included in analysis (blue horizontal lines) and firing events that are included (vertical lines color coded (10 separate colors) based on bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_beginnings = np.linspace(0, analysis_params.belt_length_mm, analysis_params.n_bins, endpoint=False)  # the mm value of the beginning of each bin\n",
    "cmap = mpl.colormaps[\"tab10\"]\n",
    "def plot_debug(i_cell):\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 24))\n",
    "    offset = 0.0\n",
    "    axs[0].imshow(binary_spiking[i_cell])\n",
    "    axs[0].set_ylim((-1, np.max(rounds)+1))\n",
    "    for round in rounds:\n",
    "        idx_current_round = lv_rounds == round\n",
    "        temporal_current_round = temporal_raw[i_cell][idx_current_round]\n",
    "        speed_current_round = lv_speed[idx_current_round]\n",
    "        included_frames_current_round = idx_filtered[idx_current_round]\n",
    "        dist_current_round = lv_distPR[idx_current_round]\n",
    "        # get all spikes that occur during the included frames\n",
    "        events_during_included_frames = np.logical_and(temporal_binary[i_cell][idx_current_round], included_frames_current_round)\n",
    "        firing_current_round = np.nonzero(events_during_included_frames) \n",
    "        \n",
    "        # get corresponding spatial bin for each firing event \n",
    "        # find first element greater than distance at which cell fired (index of next bin)\n",
    "        # subtract 1 to find the bin index\n",
    "        i_bins_events = np.searchsorted(bin_beginnings, dist_current_round[firing_current_round], side=\"right\") - 1\n",
    "        # get corresponding indices of color map \n",
    "        i_event_colors = i_bins_events%len(cmap.colors)\n",
    "        # create locomotion segments as (loco_begin_frame, loco_end_frame)\n",
    "        included_segments = []\n",
    "        i_begin_segment = 0\n",
    "        for i in range(1, len(included_frames_current_round)):\n",
    "            # detect beginning of a segment: previous frame not included, current included\n",
    "            if included_frames_current_round[i] and not included_frames_current_round[i-1]:\n",
    "                i_begin_segment = i\n",
    "            # detect end of a segment: previous frame included, current not included\n",
    "            elif not included_frames_current_round[i] and included_frames_current_round[i-1]:\n",
    "                i_end_segment = i-1\n",
    "                # end of segment found: add segment to list\n",
    "                included_segments.append((i_begin_segment, i_end_segment))\n",
    "            # for last frame: if it is part of last segment, it has to be added to that segment.\n",
    "            # If it is a new segment, this new segment of length 1 has to be added\n",
    "            elif i == len(included_frames_current_round) - 1:\n",
    "                if included_frames_current_round[i]:\n",
    "                    if included_frames_current_round[i-1]:\n",
    "                        i_end_segment = i\n",
    "                        included_segments.append((i_begin_segment, i_end_segment))\n",
    "                else:\n",
    "                    included_segments.append((i, i))\n",
    "\n",
    "        temp_min = np.min(temporal_current_round)\n",
    "        temp_max = np.max(temporal_current_round)\n",
    "        speed_min = np.min(speed_current_round)\n",
    "        speed_max = np.max(speed_current_round)\n",
    "        axs[1].hlines(y=[offset-0.05 for i in range(len(included_segments))], xmin=[included_segments[i][0] for i in range(len(included_segments))], xmax=[included_segments[i][1] for i in range(len(included_segments))], linewidth=3 )\n",
    "        # plot the locomotion velocity\n",
    "        if speed_max != speed_min:\n",
    "            axs[1].plot((speed_current_round - speed_min)/(speed_max - speed_min) + offset, color=\"grey\")\n",
    "        else:  # flat line, should be simply offset\n",
    "            axs[1].plot((speed_current_round - speed_min) + offset, color=\"grey\")\n",
    "        offset += 1.1\n",
    "        # plot scaled calcium trace\n",
    "        if temp_max != temp_min:\n",
    "            axs[1].plot((temporal_current_round - temp_min)/(temp_max - temp_min) + offset, color=\"lightgreen\")\n",
    "        else:  # flat line\n",
    "            axs[1].plot((temporal_current_round - temp_min) + offset, color=\"lightgreen\")\n",
    "        # plot all firing events that were recorded\n",
    "        axs[1].vlines(x=firing_current_round, ymin=offset-0.05, ymax=offset+1.05, linewidth=1, color=[cmap.colors[i_color] for i_color in i_event_colors])\n",
    "        offset += 1.1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_debug, i_cell=widgets.IntSlider(min=0, max=n_components-1, step=1, value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate original and shuffled mean place coding vector lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_on_belt = np.linspace(0, 2*np.pi, n_bins, endpoint=False) #initializing the circle with 150 bins corresponding to the distance on the belt\n",
    "assert len(angles_on_belt) == n_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned vector analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_tuned = np.zeros(n_units)\n",
    "shuffled_tuned_vector_lengths = np.zeros((n_units, analysis_params.n_shuffle), dtype=np.float64)\n",
    "tuned_vector_lengths = np.zeros(n_units, dtype=np.float64)\n",
    "for i_cell in range(n_units):\n",
    "    cell_spiking = binary_spiking[i_cell]\n",
    "    n_peaks=np.sum(cell_spiking)  # number of bins with firing activity TODO: make_binary(): should sum up the number of peaks in a spatial bin? Right now, it is 0 or 1\n",
    "    if n_peaks == 0:\n",
    "        continue\n",
    "    # Calculate original mean place coding vector length\n",
    "    i_rounds, i_bins = np.where(cell_spiking == 1)  # first array in tuple gives back row, second the column indices where element == 1\n",
    "    event_angles = angles_on_belt[i_bins]\n",
    "    event_radii = np.ones_like(event_angles)\n",
    "    radius_sum, angle_sum = vector_sum(event_radii, event_angles)    \n",
    "    mean_length = radius_sum/n_peaks  # normalize by number of vectors that was added up\n",
    "    mean_angle = angle_sum\n",
    "    tuned_vector_lengths[i_cell] = mean_length\n",
    "\n",
    "    # Mean vector length for shuffled data\n",
    "    mean_angles_shuffled = np.zeros(analysis_params.n_shuffle, dtype=np.float64)\n",
    "    mean_lengths_shuffled = np.zeros(analysis_params.n_shuffle, dtype=np.float64)\n",
    "    for i_shuffle in range(analysis_params.n_shuffle):\n",
    "        #shuffling every row separately\n",
    "        cell_spiking_shuffled = cell_spiking.copy()  # Make a copy to avoid modifying original data\n",
    "        for spiking_current_round in cell_spiking_shuffled:\n",
    "            np.random.shuffle(spiking_current_round)  # Shuffle the spiking events within each round independently\n",
    "        # Calculate mean direction and magnitude\n",
    "        i_rounds, i_bins = np.where(cell_spiking_shuffled == 1)  # first array in tuple gives back row, second the column indices where element == 1\n",
    "        event_angles = angles_on_belt[i_bins]\n",
    "        event_radii = np.ones_like(event_angles)\n",
    "        radius_sum, angle_sum = vector_sum(event_radii, event_angles)    \n",
    "        mean_lengths_shuffled[i_shuffle] = radius_sum/n_peaks  # normalize by number of vectors that was added up\n",
    "        mean_angles_shuffled[i_shuffle] = angle_sum\n",
    "    shuffled_tuned_vector_lengths[i_cell] = mean_lengths_shuffled\n",
    "    # calculate p-value as the percentile in which the candidate cell lies\n",
    "    # large p_value (>0.95) signifies place coding\n",
    "    p_value = np.sum(mean_lengths_shuffled <= mean_length) / analysis_params.n_shuffle\n",
    "    p_values_tuned[i_cell] = p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov test\n",
    "Compare the measured data to a random shuffle (baseline). Then compare n_shuffle shuffles to the same baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_ks = np.zeros(n_units)\n",
    "shuffled_data_ks = np.zeros((n_units, analysis_params.n_shuffle), dtype=np.float64)\n",
    "shuffled_bl_ks = np.zeros(n_units, dtype=np.float64)\n",
    "for i_cell in range(n_units):  # n_units\n",
    "    cell_spiking = binary_spiking[i_cell]\n",
    "    n_peaks=np.sum(cell_spiking)  # number of bins with firing activity TODO: make_binary(): should sum up the number of peaks in a spatial bin? Right now, it is 0 or 1\n",
    "    if n_peaks == 0:\n",
    "        continue\n",
    "    # acquire baseline\n",
    "    cell_spiking_bl = np.zeros(cell_spiking.shape)\n",
    "    for i_round in range(len(cell_spiking_bl)):\n",
    "            shift = random.randint(1, analysis_params.n_bins)\n",
    "            cell_spiking_bl[i_round] = np.roll(cell_spiking[i_round], shift)  # Shuffle the spiking events within each round independently\n",
    "    experiment_avg = np.mean(cell_spiking, axis=0)\n",
    "    baseline_avg=np.mean(cell_spiking_bl,axis=0)\n",
    "    ks_baseline,_=kstest(experiment_avg,baseline_avg)\n",
    "    shuffled_bl_ks[i_cell] = ks_baseline\n",
    "    # shuffle\n",
    "    ks_shuffled = np.zeros(analysis_params.n_shuffle)\n",
    "    for i_shuffle in range(analysis_params.n_shuffle):\n",
    "        cell_spiking_shuffled = np.zeros(cell_spiking.shape)\n",
    "        for i_round in range(len(cell_spiking_shuffled)):\n",
    "            shift = random.randint(1, analysis_params.n_bins)  # TODO: shift lower range should be 1 or 0?\n",
    "            cell_spiking_shuffled[i_round] = np.roll(cell_spiking[i_round], shift)  # Shuffle the spiking events within each round independently\n",
    "        shuffled_avg = np.mean(cell_spiking_shuffled, axis=0)\n",
    "        ks_shuffle,p_value_=kstest(baseline_avg, shuffled_avg)\n",
    "        ks_shuffled[i_shuffle] = ks_shuffle\n",
    "    shuffled_data_ks[i_cell] = ks_shuffled\n",
    "    # calculate p value\n",
    "    p_value_ks = np.sum(ks_shuffled > ks_baseline) / len(ks_shuffled)\n",
    "    p_values_ks[i_cell] = p_value_ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make an ultimate debug plot:\n",
    "# plot the trace per each round, and underline the frames that are included for analysis (when I do cuts, also cut for the frame indices in the end).\n",
    "# Plot locomotion as well, to see that only frames with locomotion are included. Also plot the binary spikes. Then plot the spatial bins too? \n",
    "# As vlines or different colored spikes for each spatial bin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firing rate per bin\n",
    "Columns:  cell no., bin index, avg firing rate over rounds, p_tuning, p_ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firing rate per cell per round per bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_entries = frm_z.flatten().shape[0]\n",
    "cell_ids = np.zeros(frm_z.shape, dtype=np.int16)\n",
    "rounds = np.zeros(frm_z.shape, dtype=np.int16)\n",
    "bin_idxs = np.zeros(frm_z.shape, dtype=np.int16)\n",
    "# TODO loop over cells, rounds, and bins, add cell_id, round, bin_idx, firing_rate\n",
    "for i_cell in range(n_units):\n",
    "    cell_ids[i_cell] = np.full((frm_z.shape[1], frm_z.shape[2]), i_cell, dtype=np.int16)\n",
    "    for i_round in range(frm_z.shape[1]):\n",
    "        rounds[i_cell][i_round] = np.full(frm_z.shape[2], i_round, dtype=np.int16)\n",
    "        bin_idxs[i_cell][i_round] = np.linspace(0, frm_z_avg.shape[1], num=frm_z_avg.shape[1], endpoint=False, dtype=np.int16)\n",
    "dict_fr={\"cell_id\":cell_ids.flatten(), \"round\":rounds.flatten(), \"bin_idx\":bin_idxs.flatten(), \"firing_rate\":binary_spiking.flatten()}\n",
    "df_firing_rate = pd.DataFrame(dict_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaged firing rate over rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_entries = frm_z_avg.flatten().shape[0]\n",
    "cell_ids = np.zeros(frm_z_avg.shape, dtype=np.int16)\n",
    "bin_idxs = np.zeros(frm_z_avg.shape, dtype=np.int16)\n",
    "# TODO loop over cells, rounds, and bins, add cell_id, round, bin_idx, firing_rate\n",
    "for i_cell in range(n_units):\n",
    "    cell_ids[i_cell] = np.full(frm_z_avg.shape[1], i_cell)\n",
    "    bin_idxs[i_cell] = np.linspace(0, frm_z_avg.shape[1], num=frm_z_avg.shape[1], endpoint=False, dtype=np.int16)\n",
    "dict_fr={\"cell_id\":cell_ids.flatten(), \"bin_idx\":bin_idxs.flatten(), \"firing_rate\":frm_z_avg.flatten()}\n",
    "df_avg_firing_rate = pd.DataFrame(dict_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P values per cell for both methods and bin index for first maximum of firing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_p_vals = {\"cell_id\": np.array([i for i in range(n_units)]), \"i_fr_max\": np.argmax(frm_z_avg, axis=1), \"p_tuning\": p_values_tuned, \"p_ks\": p_values_ks}\n",
    "df_p_values = pd.DataFrame(data=dict_p_vals)\n",
    "del dict_p_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_firing_rate = df_avg_firing_rate.join(df_p_values, how=\"left\", on=\"cell_id\", rsuffix=\"_other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot firing rate over belt for place cells vs non-place cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned vector method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_firing_rate_accepted = df_avg_firing_rate[df_avg_firing_rate[\"p_tuning\"] > 0.95].join(df_p_values, on=\"cell_id\", how=\"left\", rsuffix=\"_other\").sort_values(by=[\"i_fr_max\", \"bin_idx\"]).pivot_table(index=\"cell_id\", columns=\"bin_idx\", values=\"firing_rate\", sort=False)\n",
    "pivot_firing_rate_rejected = df_avg_firing_rate[df_avg_firing_rate[\"p_tuning\"] <= 0.95].join(df_p_values, on=\"cell_id\", how=\"left\", rsuffix=\"_other\").sort_values(by=[\"i_fr_max\", \"bin_idx\"]).pivot_table(index=\"cell_id\", columns=\"bin_idx\", values=\"firing_rate\", sort=False)\n",
    "\n",
    "f, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
    "sns.heatmap(pivot_firing_rate_accepted, ax=axs[0])\n",
    "sns.heatmap(pivot_firing_rate_rejected, ax=axs[1])\n",
    "\n",
    "axs[0].set_title(\"accepted\")\n",
    "axs[1].set_title(\"rejected\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KS method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_firing_rate_accepted = df_avg_firing_rate[df_avg_firing_rate[\"p_ks\"] > 0.05].join(df_p_values, on=\"cell_id\", how=\"left\", rsuffix=\"_other\").sort_values(by=[\"i_fr_max\", \"bin_idx\"]).pivot_table(index=\"cell_id\", columns=\"bin_idx\", values=\"firing_rate\", sort=False)\n",
    "pivot_firing_rate_rejected = df_avg_firing_rate[df_avg_firing_rate[\"p_ks\"] <= 0.05].join(df_p_values, on=\"cell_id\", how=\"left\", rsuffix=\"_other\").sort_values(by=[\"i_fr_max\", \"bin_idx\"]).pivot_table(index=\"cell_id\", columns=\"bin_idx\", values=\"firing_rate\", sort=False)\n",
    "\n",
    "f, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
    "sns.heatmap(pivot_firing_rate_accepted, ax=axs[0])\n",
    "sns.heatmap(pivot_firing_rate_rejected, ax=axs[1])\n",
    "axs[0].set_title(\"accepted\")\n",
    "axs[1].set_title(\"rejected\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell-specific figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cell = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity per round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot_firing_rate_accepted = df_avg_firing_rate[df_avg_firing_rate[\"p_ks\"] > 0.05].join(df_p_values, on=\"cell_id\", how=\"left\", rsuffix=\"_other\").sort_values(by=[\"i_fr_max\", \"bin_idx\"]).pivot_table(index=\"cell_id\", columns=\"bin_idx\", values=\"firing_rate\", sort=False)\n",
    "pivot_table_single = df_firing_rate[df_firing_rate[\"cell_id\"] == i_cell].pivot_table(columns=\"bin_idx\", index=\"round\", values=\"firing_rate\")\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(pivot_table_single, ax=ax)\n",
    "ax.set_title(f\"Cell #{i_cell}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(12, 4))\n",
    "axs[0].hist(shuffled_tuned_vector_lengths[i_cell])\n",
    "axs[1].hist(shuffled_data_ks[i_cell])\n",
    "\n",
    "axs[0].vlines(x=tuned_vector_lengths[i_cell], ymin=0, ymax=100, color=\"red\")\n",
    "axs[1].vlines(x=shuffled_bl_ks[i_cell], ymin=0, ymax=100, color=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circular plotting of activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cell = 359\n",
    "binary_spiking_cell = binary_spiking[i_cell]\n",
    "n_bins = len(binary_spiking_cell[0])\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.set_xlabel('Angle (degrees)')\n",
    "ax.set_ylabel('Radius')\n",
    "for i_round in range(len(binary_spiking_cell)):\n",
    "    i_firing_bins = binary_spiking_cell[i_round].nonzero()[0]\n",
    "    if len(i_firing_bins) > 0:\n",
    "        vector_length = i_round + 1  # avoid 0 length\n",
    "        vector_lengths = [vector_length]*len(i_firing_bins)\n",
    "        firing_angles_deg = i_firing_bins*360./n_bins\n",
    "        ax.scatter(firing_angles_deg, vector_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(i_cell):\n",
    "    pivot_table_single = df_firing_rate[df_firing_rate[\"cell_id\"] == i_cell].pivot_table(columns=\"bin_idx\", index=\"round\", values=\"firing_rate\")\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    binary_spiking_cell = binary_spiking[i_cell]\n",
    "    n_bins = len(binary_spiking_cell[0])\n",
    "    ax1 = plt.subplot(221)\n",
    "    ax2 = plt.subplot(222, projection='polar')\n",
    "    ax3 = plt.subplot(223)\n",
    "    ax4  =plt.subplot(224)\n",
    "    sns.heatmap(pivot_table_single, ax=ax1)\n",
    "    ax2.set_xlabel('Angle (degrees)')\n",
    "    ax2.set_ylabel('Round')\n",
    "    for i_round in range(len(binary_spiking_cell)):\n",
    "        i_firing_bins = binary_spiking_cell[i_round].nonzero()[0]\n",
    "        if len(i_firing_bins) > 0:\n",
    "            vector_length = i_round + 1  # avoid 0 length\n",
    "            vector_lengths = [vector_length]*len(i_firing_bins)\n",
    "            firing_angles_deg = i_firing_bins*360./n_bins\n",
    "            ax2.scatter(firing_angles_deg, vector_lengths)\n",
    "    ax2.set_ylim((0, len(binary_spiking_cell)+0.2))\n",
    "    ax1.set_title(f\"Cell #{i_cell}\")\n",
    "    ax3.hist(shuffled_tuned_vector_lengths[i_cell], bins=20)\n",
    "    ax4.hist(shuffled_data_ks[i_cell], bins=20)\n",
    "    ax3.vlines(x=tuned_vector_lengths[i_cell], ymin=0, ymax=100, color=\"red\")\n",
    "    ax4.vlines(x=shuffled_bl_ks[i_cell], ymin=0, ymax=100, color=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_data, i_cell=widgets.IntSlider(min=df_firing_rate['cell_id'].min(), max=df_firing_rate['cell_id'].max(), step=1, value=df_firing_rate['cell_id'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_output = os.path.join(output_folder, os.path.splitext(os.path.split(fpath_expinfo)[-1])[0].replace(\"expinfo\", \"placecoding\")+\".h5\")\n",
    "print(f\"Saving to {fpath_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_results:\n",
    "    with h5py.File(fpath_output, \"w\") as hf:\n",
    "        dict_analysis_params = analysis_params.to_dict()\n",
    "        for key in dict_analysis_params.keys():\n",
    "            hf.attrs[key] = dict_analysis_params[key]\n",
    "        hf.create_dataset(\"frm_raw\", data=frm_raw)\n",
    "        hf.create_dataset(\"frm_z\", data=frm_z)\n",
    "        hf.create_dataset(\"binary_spiking\", data=binary_spiking)\n",
    "        hf.create_dataset(\"tuned_vector_lengths\", data=tuned_vector_lengths)\n",
    "        hf.create_dataset(\"shuffled_tuned_vector_lengths\", data=shuffled_tuned_vector_lengths)\n",
    "        hf.create_dataset(\"p_values_tuned\", data=p_values_tuned)\n",
    "        hf.create_dataset(\"shuffled_data_ks\", data=shuffled_data_ks)\n",
    "        hf.create_dataset(\"shuffled_bl_ks\", data=shuffled_bl_ks)\n",
    "        hf.create_dataset(\"p_values_ks\", data=p_values_ks)\n",
    "        # TODO: add spatial components (to make it a standalone file) as sparse matrix\n",
    "    print(f\"Saved to {fpath_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "placecoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
